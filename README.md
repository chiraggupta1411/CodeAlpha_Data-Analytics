**ğŸ“Š CodeAlpha Data Analytics Internship â€” Project Repository**

Welcome to my CodeAlpha Data Analytics Internship repository.

This repository contains all four completed tasks covering Web Scraping, Exploratory Data Analysis (EDA), Data Visualization, and Sentiment Analysis.

Each task demonstrates practical industry-level data analytics skills using Python, Pandas, Matplotlib, BeautifulSoup, Requests, and NLP tools.

ğŸš€ Tasks Included

ğŸŒ Task 1 â€” Web Scraping (IMDb Top 250)

This task focuses on extracting structured data from the IMDb Top 250 Movies page.

âœ” Highlights

Scrapes movie Rank, Title, Year, Rating, IMDb ID, URL

Saves data in CSV, JSON, and Excel formats

Includes fallback Selenium script for dynamic content

Demonstrates clean and adaptable web-scraping workflow

âœ” Technologies

Requests, BeautifulSoup, Pandas, (Optional) Selenium

ğŸ“ˆ Task 2 â€” Exploratory Data Analysis (IPL Dataset)

Performed Exploratory Data Analysis on the IPL (2008â€“2025) dataset.

âœ” Highlights

Data cleaning & preprocessing

Statistical insights

Trends across seasons

Top teams, top players, match outcomes

Hypothesis testing

Detecting anomalies and patterns

âœ” Technologies

Pandas, NumPy, Matplotlib, Seaborn, SciPy

ğŸ“Š Task 3 â€” Data Visualization (IPL Dataset)

Created meaningful visualizations for insights from the IPL dataset.

âœ” Visuals Included

Wins by team

Matches per season

Toss decision analysis

Venue popularity

Top batsmen (if available)

Saved in output_visuals/

âœ” Technologies

Matplotlib, Seaborn, Pandas

ğŸ“ Task 4 â€” Sentiment Analysis

Applied NLP-based sentiment analysis on a dataset of text reviews.

âœ” Highlights

Text cleaning & preprocessing

Polarity & subjectivity scoring using TextBlob

Classifies sentiment into Positive, Negative, Neutral

Visualization of sentiment distribution

Saves processed dataset in sentiment_output/

âœ” Technologies

TextBlob, Pandas, Matplotlib, Seaborn

ğŸ“ Repository Structure

CodeAlpha_Data-Analytics/

â”‚

â”œâ”€â”€ Task_1_Web_Scraping/

â”‚   â”œâ”€â”€ web_scraping.py

â”‚   â”œâ”€â”€ imdb_top250.csv / .json / .xlsx

â”‚

â”œâ”€â”€ Task_2_IPL_EDA/

â”‚   â”œâ”€â”€ ipl_eda.py

â”‚   â”œâ”€â”€ output/

â”‚

â”œâ”€â”€ Task_3_IPL_Visualization/

â”‚   â”œâ”€â”€ ipl_visualization.py

â”‚   â”œâ”€â”€ output_visuals/

â”‚

â”œâ”€â”€ Task_4_Sentiment_Analysis/

â”‚   â”œâ”€â”€ sentiment_analysis.py

â”‚   â”œâ”€â”€ sentiment_output/

â”‚

â””â”€â”€ README.md

ğŸ› ï¸ Installation & Setup

Clone the repository:

git clone https://github.com/chiraggupta1411/CodeAlpha_Data-Analytics

cd CodeAlpha_Data-Analytics

Install required dependencies:

pip install -r requirements.txt

(If requirements file is not added, manually install libraries mentioned in each task.)

ğŸ¯ Outcome

This repository showcases the end-to-end workflow of a Data Analyst:

âœ” Data collection (Web Scraping)

âœ” Data cleaning & preprocessing

âœ” Exploratory Data Analysis

âœ” Data Visualization

âœ” NLP-based Sentiment Analysis

âœ” Python scripting and automation


It demonstrates strong practical analytical skills suitable for real-world projects.

ğŸ¤ Connect With Me

ğŸ”— GitHub: https://github.com/chiraggupta1411

ğŸ’¼ Open to collaborations in Data Analysis, AI, and Python-based projects.
